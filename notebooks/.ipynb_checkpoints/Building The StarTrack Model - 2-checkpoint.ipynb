{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae55e43b-2f36-4038-8bfc-cf3d4b6e4511",
   "metadata": {},
   "source": [
    "# Building The StarTrack Model - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "134bd825-bad2-43f8-9192-edfbd756e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79e77679-0feb-4047-9e15-9a2a2101710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b24cea5d-66b0-4327-b5c0-a8889dbcebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data = pd.read_csv('../data/processed_data.csv')\n",
    "spectrogram_data = np.load('../data/startrack_spectrograms.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e332ba8f-6aec-4fe1-a850-bf2f7282ee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ELODIE_TEFF</th>\n",
       "      <th>ELODIE_LOGG</th>\n",
       "      <th>ELODIE_FEH</th>\n",
       "      <th>Z</th>\n",
       "      <th>Z_ERR</th>\n",
       "      <th>ZWARNING</th>\n",
       "      <th>VDISP</th>\n",
       "      <th>VDISP_ERR</th>\n",
       "      <th>SN_MEDIAN_ALL</th>\n",
       "      <th>RCHI2</th>\n",
       "      <th>DOF</th>\n",
       "      <th>SNR_Bin</th>\n",
       "      <th>High_Quality</th>\n",
       "      <th>Mean_Flux</th>\n",
       "      <th>Flux_to_Noise</th>\n",
       "      <th>u_flux</th>\n",
       "      <th>g_flux</th>\n",
       "      <th>r_flux</th>\n",
       "      <th>i_flux</th>\n",
       "      <th>z_flux</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_median</th>\n",
       "      <th>flux_p25</th>\n",
       "      <th>flux_p75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3705.0</td>\n",
       "      <td>4.800</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.000485</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.021759</td>\n",
       "      <td>0.880377</td>\n",
       "      <td>4542</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.168239</td>\n",
       "      <td>1.953985</td>\n",
       "      <td>0.269059</td>\n",
       "      <td>0.268631</td>\n",
       "      <td>0.195929</td>\n",
       "      <td>0.125402</td>\n",
       "      <td>0.047316</td>\n",
       "      <td>37.168239</td>\n",
       "      <td>10.325851</td>\n",
       "      <td>19.371477</td>\n",
       "      <td>46.528843</td>\n",
       "      <td>42.201336</td>\n",
       "      <td>31.882357</td>\n",
       "      <td>45.857182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3705.0</td>\n",
       "      <td>4.800</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.828102</td>\n",
       "      <td>1.034391</td>\n",
       "      <td>4487</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.272045</td>\n",
       "      <td>1.764143</td>\n",
       "      <td>0.313935</td>\n",
       "      <td>0.310882</td>\n",
       "      <td>0.236147</td>\n",
       "      <td>0.178934</td>\n",
       "      <td>0.105151</td>\n",
       "      <td>40.272045</td>\n",
       "      <td>11.563604</td>\n",
       "      <td>20.819483</td>\n",
       "      <td>51.774773</td>\n",
       "      <td>44.854801</td>\n",
       "      <td>33.856216</td>\n",
       "      <td>50.054951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3705.0</td>\n",
       "      <td>4.800</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.743233</td>\n",
       "      <td>0.948585</td>\n",
       "      <td>4505</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>67.842227</td>\n",
       "      <td>2.360285</td>\n",
       "      <td>0.630979</td>\n",
       "      <td>0.791056</td>\n",
       "      <td>0.716503</td>\n",
       "      <td>0.637338</td>\n",
       "      <td>0.519138</td>\n",
       "      <td>67.842227</td>\n",
       "      <td>21.698880</td>\n",
       "      <td>31.049629</td>\n",
       "      <td>89.325089</td>\n",
       "      <td>76.546692</td>\n",
       "      <td>56.288620</td>\n",
       "      <td>86.001106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3705.0</td>\n",
       "      <td>4.800</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.706001</td>\n",
       "      <td>0.875567</td>\n",
       "      <td>4568</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.974394</td>\n",
       "      <td>1.728440</td>\n",
       "      <td>0.263392</td>\n",
       "      <td>0.306808</td>\n",
       "      <td>0.250842</td>\n",
       "      <td>0.196867</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>40.974394</td>\n",
       "      <td>13.044562</td>\n",
       "      <td>19.188595</td>\n",
       "      <td>54.732037</td>\n",
       "      <td>45.824268</td>\n",
       "      <td>33.665863</td>\n",
       "      <td>51.461208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9899.0</td>\n",
       "      <td>2.924</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.716969</td>\n",
       "      <td>0.984394</td>\n",
       "      <td>4395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.968928</td>\n",
       "      <td>1.092735</td>\n",
       "      <td>-0.283738</td>\n",
       "      <td>-0.361274</td>\n",
       "      <td>-0.387023</td>\n",
       "      <td>-0.406692</td>\n",
       "      <td>-0.432778</td>\n",
       "      <td>2.968928</td>\n",
       "      <td>0.924360</td>\n",
       "      <td>1.534235</td>\n",
       "      <td>4.132542</td>\n",
       "      <td>2.982392</td>\n",
       "      <td>2.454889</td>\n",
       "      <td>3.740581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ELODIE_TEFF  ELODIE_LOGG  ELODIE_FEH         Z     Z_ERR  ZWARNING  VDISP  \\\n",
       "0       3705.0        4.800        0.60 -0.000485  0.000014         0    0.0   \n",
       "1       3705.0        4.800        0.60 -0.000195  0.000015         0    0.0   \n",
       "2       3705.0        4.800        0.60  0.000728  0.000011         0    0.0   \n",
       "3       3705.0        4.800        0.60  0.000277  0.000016         0    0.0   \n",
       "4       9899.0        2.924        0.09  0.000616  0.000081         0    0.0   \n",
       "\n",
       "   VDISP_ERR  SN_MEDIAN_ALL     RCHI2   DOF  SNR_Bin  High_Quality  Mean_Flux  \\\n",
       "0        0.0      19.021759  0.880377  4542      2.0             0  37.168239   \n",
       "1        0.0      22.828102  1.034391  4487      3.0             1  40.272045   \n",
       "2        0.0      28.743233  0.948585  4505      3.0             1  67.842227   \n",
       "3        0.0      23.706001  0.875567  4568      3.0             1  40.974394   \n",
       "4        0.0       2.716969  0.984394  4395      0.0             0   2.968928   \n",
       "\n",
       "   Flux_to_Noise    u_flux    g_flux    r_flux    i_flux    z_flux  flux_mean  \\\n",
       "0       1.953985  0.269059  0.268631  0.195929  0.125402  0.047316  37.168239   \n",
       "1       1.764143  0.313935  0.310882  0.236147  0.178934  0.105151  40.272045   \n",
       "2       2.360285  0.630979  0.791056  0.716503  0.637338  0.519138  67.842227   \n",
       "3       1.728440  0.263392  0.306808  0.250842  0.196867  0.137755  40.974394   \n",
       "4       1.092735 -0.283738 -0.361274 -0.387023 -0.406692 -0.432778   2.968928   \n",
       "\n",
       "    flux_std   flux_min   flux_max  flux_median   flux_p25   flux_p75  \n",
       "0  10.325851  19.371477  46.528843    42.201336  31.882357  45.857182  \n",
       "1  11.563604  20.819483  51.774773    44.854801  33.856216  50.054951  \n",
       "2  21.698880  31.049629  89.325089    76.546692  56.288620  86.001106  \n",
       "3  13.044562  19.188595  54.732037    45.824268  33.665863  51.461208  \n",
       "4   0.924360   1.534235   4.132542     2.982392   2.454889   3.740581  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = [\"Unnamed: 0\", \"Unnamed: 0.1\", \"Unnamed: 0.3\", \"Unnamed: 0.2\",\n",
    "                   \"CLASS\", \"SUBCLASS\", \"SUBCLASS_CLEAN\", \"SPECTRAL_GROUP\", \n",
    "                   \"url\", \"filename\", \"PLATE\", \"MJD\", \"FIBERID\", \"ELODIE_SPTYPE\" ]\n",
    "labels_tabular = tabular_data[\"SPECTRAL_GROUP\"]\n",
    "tabular_data = tabular_data.drop(columns=columns_to_drop)\n",
    "pd.set_option('display.max_columns', None)\n",
    "bin_dict = {'Very Low': 0, 'Low': 1, 'Moderate': 2, 'Good': 3, 'High': 4, 'Very High': 5}\n",
    "tabular_data[\"SNR_Bin\"] = tabular_data[\"SNR_Bin\"].map(bin_dict)\n",
    "qual_dict = {False: 0, True: 1} # There's probably a better way to do this not going to lie\n",
    "tabular_data[\"High_Quality\"] = tabular_data[\"High_Quality\"].map(qual_dict)\n",
    "tabular_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e7cbe93-539b-46af-8096-5feaede2a486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24782, 27)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef478b36-8b05-4be6-b351-62e2d9a2c090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    F\n",
       "1    F\n",
       "2    F\n",
       "3    F\n",
       "4    F\n",
       "Name: SPECTRAL_GROUP, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tabular.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff694b91-10f9-4bf0-b2c0-05d454a1dd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24782, 1024)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrograms = spectrogram_data[\"spectrograms\"] \n",
    "labels_spect = spectrogram_data[\"labels\"] \n",
    "spectrograms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3b28d3e-18dc-41ac-95c1-75258ff2f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method taken from my EchoScope project, check it out here: https://github.com/blueskinlizard/EchoScope/tree/main\n",
    "def split_sets(X, y):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "    \n",
    "    print(f'Train shape: {X_train.shape}, {y_train.shape}')\n",
    "    print(f'Validation shape: {X_val.shape}, {y_val.shape}')\n",
    "    print(f'Test shape: {X_test.shape}, {y_test.shape}')\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0b1fa7e-7e66-4582-9f14-9c6bee61af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method also taken from EchoScope\n",
    "def train_model(model, criterion, optimizer, epochs, train_loader, val_loader, patience=5, scheduler=None):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    no_improve_epochs = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=False)\n",
    "        for X_batch, y_batch in train_bar:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            train_bar.set_postfix(loss=loss.item())\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} [Val]\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_bar:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "                val_bar.set_postfix(loss=loss.item())\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Val\", val_loss, epoch)\n",
    "        writer.add_scalar(\"LR\", optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} (best val loss: {best_val_loss:.6f})\")\n",
    "                break\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "    model.load_state_dict(best_model_state)\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f56ecbb9-19e9-4dcb-8d2f-425f9f438d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method also taken from EchoScope\n",
    "def set_seed(seed=1):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ad8e7-0681-4dfa-a46a-3885e28655b2",
   "metadata": {},
   "source": [
    "# Training The Dense (Tabular Data) branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70d35bb9-1092-4375-87e4-22a51fa4a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (24782, 27)\n",
      "Total samples: 24782\n",
      "Unique classes: ['A' 'B' 'CV' 'F' 'G' 'K' 'L' 'M' 'WD']\n"
     ]
    }
   ],
   "source": [
    "le_tabular = LabelEncoder()\n",
    "labels_encoded_tabular = le_tabular.fit_transform(labels_tabular)\n",
    "X = tabular_data\n",
    "y = labels_encoded_tabular\n",
    "print(\"X shape:\", X.shape)\n",
    "print(f'Total samples: {X.shape[0]}')\n",
    "print(f'Unique classes: {le_tabular.classes_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cecd38a-4be5-48f9-9d04-0d6d2be9a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (14868, 27), (14868,)\n",
      "Validation shape: (4957, 27), (4957,)\n",
      "Test shape: (4957, 27), (4957,)\n"
     ]
    }
   ],
   "source": [
    "X_table_train, y_table_train, X_table_val, y_table_val, X_table_test, y_table_test = split_sets(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17913a10-2f9e-46a7-b0a9-99925117e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_table_train_fusion = X_table_train.copy()\n",
    "X_table_val_fusion = X_table_val.copy()\n",
    "X_table_test_fusion = X_table_test.copy()\n",
    "\n",
    "y_table_train_fusion = y_table_train.copy()\n",
    "y_table_val_fusion = y_table_val.copy()\n",
    "y_table_test_fusion = y_table_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fe42595-1ea9-4329-ba6a-6422c69c2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_table_np = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X_table_train.values, dtype=torch.float32),\n",
    "    torch.tensor(y_table_train, dtype=torch.long)\n",
    ")\n",
    "\n",
    "val_dataset_table_np = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X_table_val.values, dtype=torch.float32),\n",
    "    torch.tensor(y_table_val, dtype=torch.long)\n",
    ")\n",
    "\n",
    "test_dataset_table_np = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X_table_test.values, dtype=torch.float32),\n",
    "    torch.tensor(y_table_test, dtype=torch.long)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a10c6ab-e5e8-4953-9c2d-62a1d585c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_tabular = DataLoader(train_dataset_table_np, batch_size=64, shuffle=True)\n",
    "val_loader_tabular = DataLoader(val_dataset_table_np, batch_size=64, shuffle=True)\n",
    "test_loader_tabular = DataLoader(test_dataset_table_np, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdb61258-aafd-4f9e-8bda-03061af68fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarTrack_Dense(nn.Module):\n",
    "    def __init__(self, input_size=22, hidden_sizes=[128, 64], output_size=9):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.out = nn.Linear(hidden_sizes[1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    def extract_features(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "898b85b5-b7ce-4544-84f4-d4a822f3ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "StarTrack_Dense_V1 = StarTrack_Dense()\n",
    "StarTrack_Dense_V1 = StarTrack_Dense_V1 .to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2718405-1895-4d15-91b7-311031f455e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radiant\\AppData\\Local\\Temp\\ipykernel_13024\\3309839688.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  class_weights_dense = torch.tensor(class_weights, dtype=torch.float).to(device)\n"
     ]
    }
   ],
   "source": [
    "class_weights_dense = compute_class_weight('balanced', classes=np.unique(y_table_train), y=y_table_train)\n",
    "class_weights_dense = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_dense)\n",
    "optimizer_dense = torch.optim.Adam(StarTrack_Dense_V1.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9bcee-2472-4c5b-bb58-c1ae82e9e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_dense, val_losses_dense = train_model(model=StarTrack_Dense_V1, \n",
    "                                       criterion=loss_fn, \n",
    "                                       optimizer=optimizer, \n",
    "                                       epochs=15, \n",
    "                                       train_loader=train_loader_tabular, \n",
    "                                       val_loader=val_loader_tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00bcfbc-0a6a-4812-8603-54754781374c",
   "metadata": {},
   "source": [
    "# Training The LSTM (Spectrogram) Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3df82de-e34a-4594-8577-ade7e4409518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (24782, 1024, 1)\n",
      "Total samples: 24782\n",
      "Unique classes: ['A' 'B' 'CV' 'F' 'G' 'K' 'L' 'M' 'WD']\n"
     ]
    }
   ],
   "source": [
    "le_spect = LabelEncoder()\n",
    "labels_encoded_spect = le_spect.fit_transform(labels_spect)\n",
    "X = spectrograms\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "y = labels_encoded_spect\n",
    "print(\"X shape:\", X.shape)\n",
    "print(f'Total samples: {X.shape[0]}')\n",
    "print(f'Unique classes: {le_spect.classes_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4b5b88b-d3d2-4a58-989a-e9d97204f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (14868, 1024, 1), (14868,)\n",
      "Validation shape: (4957, 1024, 1), (4957,)\n",
      "Test shape: (4957, 1024, 1), (4957,)\n"
     ]
    }
   ],
   "source": [
    "X_spect_train, y_spect_train, X_spect_val, y_spect_val, X_spect_test, y_spect_test = split_sets(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "beba80f3-86b2-4e87-bdb0-8c6979f94aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spect_train_fusion = X_spect_train.copy()\n",
    "X_spect_val_fusion = X_spect_val.copy()\n",
    "X_spect_test_fusion = X_spect_test.copy()\n",
    "\n",
    "y_spect_train_fusion = y_spect_train.copy()\n",
    "y_spect_val_fusion = y_spect_val.copy()\n",
    "y_spect_test_fusion = y_spect_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c65a697b-b234-4558-8be5-f84d83b34749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_spect = TensorDataset(torch.tensor(X_spect_train, dtype=torch.float32), torch.tensor(y_spect_train, dtype=torch.long))\n",
    "val_dataset_spect = TensorDataset(torch.tensor(X_spect_val, dtype=torch.float32), torch.tensor(y_spect_val, dtype=torch.long))\n",
    "test_dataset_spect = TensorDataset(torch.tensor(X_spect_test, dtype=torch.float32), torch.tensor(y_spect_test, dtype=torch.long))\n",
    "\n",
    "train_loader_spect = DataLoader(train_dataset_time, batch_size=64, shuffle=True)\n",
    "val_loader_spect = DataLoader(val_dataset_time, batch_size=64, shuffle=False)\n",
    "test_loader_spect = DataLoader(test_dataset_time, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "667fc7ed-07f5-4513-8028-1e588aa5570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader needs (B, 1024, 1) shape\n",
    "class StarTrack_LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=256, output_size=9, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=0.5, # Lower/Increase based off testing results\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(hidden_size*2)\n",
    "        self.fc1 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "        \n",
    "# Number of classes after grouping = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78b47032-e624-4c0f-8a9f-1194e237c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "StarTrack_LSTM_V1 = StarTrack_LSTM()\n",
    "StarTrack_LSTM_V1 = StarTrack_LSTM_V1 .to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64f83968-dd5e-4983-b87b-eb13516168eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radiant\\AppData\\Local\\Temp\\ipykernel_13024\\3703655229.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  class_weights_LSTM = torch.tensor(class_weights, dtype=torch.float).to(device)\n"
     ]
    }
   ],
   "source": [
    "class_weights_LSTM = compute_class_weight('balanced', classes=np.unique(y_spect_train), y=y_spect_train)\n",
    "class_weights_LSTM = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_LSTM)\n",
    "optimizer_LSTM = torch.optim.Adam(StarTrack_LSTM_V1.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6e71d-449b-4858-82af-137bd2ad5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_LSTM, val_losses_LSTM= train_model(model=StarTrack_LSTM_V1, \n",
    "                                       criterion=loss_fn, \n",
    "                                       optimizer=optimizer_LSTM, \n",
    "                                       epochs=15, \n",
    "                                       train_loader=train_loader_spect, \n",
    "                                       val_loader=val_loader_spect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0fe52-fd72-4dde-8299-d3e0b8766691",
   "metadata": {},
   "source": [
    "# Training The Fusion Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40c370-198a-4b03-ba17-ea9425edcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarTrack_Fusion(nn.Module):\n",
    "    def __init__(self, lstm_model: nn.Module, dense_model: nn.Module,\n",
    "                 fused_hidden_dim=512, num_classes=9): \n",
    "        super().__init__()\n",
    "        self.lstm_branch = lstm_model\n",
    "        self.dense_branch = dense_model\n",
    "\n",
    "        for param in self.lstm_branch.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.dense_branch.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        for param in self.lstm_branch.fc1.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.dense_branch.fc1.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        lstm_output_dim = 256\n",
    "        dense_output_dim = 64\n",
    "        \n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=lstm_output_dim, num_heads=4)\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim + dense_output_dim, fused_hidden_dim),\n",
    "            nn.GELU(),  \n",
    "            nn.BatchNorm1d(fused_hidden_dim),\n",
    "            nn.Linear(fused_hidden_dim, fused_hidden_dim//2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3), \n",
    "            nn.Linear(fused_hidden_dim//2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.lstm_classifier = nn.Linear(lstm_output_dim, num_classes)\n",
    "        self.dense_classifier = nn.Linear(dense_output_dim, num_classes)\n",
    "        self.dense_proj = nn.Linear(dense_output_dim, lstm_output_dim)\n",
    "\n",
    "    def forward(self, lstm_input, dense_input):\n",
    "            lstm_feat = self.lstm_branch.extract_features(lstm_input)\n",
    "            dense_feat = self.dense_branch.extract_features(dense_input)\n",
    "        \n",
    "            lstm_q = lstm_feat.unsqueeze(0)  \n",
    "            dense_kv = dense_proj.unsqueeze(0)  \n",
    "\n",
    "            dense_proj = self.dense_proj(dense_feat) \n",
    "           \n",
    "            attn_out, _ = self.cross_attn(query=lstm_q, key=dense_kv, value=dense_kv)\n",
    "            attn_out = attn_out.squeeze(0)\n",
    "        \n",
    "            lstm_feat = lstm_feat + attn_out      \n",
    "            fused = torch.cat([lstm_feat, dense_feat], dim=1) \n",
    "            out = self.fusion(fused)\n",
    "        \n",
    "            lstm_out = self.lstm_classifier(lstm_feat)\n",
    "            dense_out = self.dense_classifier(dense_feat)\n",
    "            return out, lstm_out, dense_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ce593-8293-412b-8d77-0de497cbdd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
